; test validation
; SNR < 1 to SNR > 1000 ok. at bin = 1, convolve at bin=1, kernel at bin=3
; - test background
; - test shift / rotation
; - binning
;   + x3 storage

; badness:
; -> check rotated PSF i=31, 6977
; and   6977, 6898,7214,7225,7238
; -- @@ checked both aor_pa flip and kernel 180 rotation flip -> clearly worse
; -- @@@ need to check PSF orientation -> go back to IRAC Oars, det deep stack (e.g. in HUDF
;     and trace rotations and residuals

; do aperture photometry, instrumental counts

; tasks:
; - photometry
;    + aperture photometry, colors, total
;    + circular, elliptical
; - fitting photometry based on subphot
;   + best-fit (force > positive or not?)
;   + aperture matched photometry: best-fit + inproduct of tmpl + residual map (what is error?)
;   + use covariance matrix? to indicate quality -> check tphot?
;
; - allowed models:
;   + autogenerated from det image (segmap or deblended)
;   + allow reading in a theoretical prior from file (ID_tmpl.fits -> not PSF convolved)
;     get pixel scale from header
;   + unresolved point-like priors: a catalog of positions (ra,dec,or x,y)
;     can decide on point vs not, by examining the FWHM.
;     model type: segment, blend, model, point
;   + select type in input catalog
;
; - no file buffering, just accepts an image and optional header
;   + will do internal buffering for efficiency
;
; - save photometry image in model pixel units
;   + PSF FWHM is sampled by 5 pixels
;   + photometry image is sampled by at least original pixel scale
;
; - PSF: as provided by psf, interpolated coefficients on a grid of ra,dec
;   +, also store original coefficients
;   + allow irregular interpolation if desired
;
; - don't generate for diagnostics for all, only after run for selected.
; @@ write diagnostic viewer, if ying,yang -> regul. check sources with large shifts -> update position
;
; - shifts: faulty shifts ? replace by local interpolated?
;   + cross correlation based on first pass fit
;   + inverse shift the photometry image
;     do not apply the shift we want to fft only once
;
; - kernels: don't recompute for each object.
;   + make map at a 2 finer grid than in PSF map
;   + precompute PSF grid
;   + pull from memory
;
; - extended wings van foreground galaxies.
;
; - FFT convolutions: ignore aliasing, except boundary,
;    + at single precision residuals are at level 1e-7
;      so set a dynamic range threshold of 1e-5 * rms, if higher -> pad x2
;      otherwise use the padding provided by fconvolve (> center array?)
;;
; - TFIT/TPHOT possibilies:
;   +  overlapping grid cell (cells on objects), separate fit and choose the one closer to the center
;   + convphot method: image as a whole (sparse)
;   + cells on objects: sort by brightness, build cell on object enlarge to include overlapping sources.
;     -> subtract object: they claim that because of reducing the catalog by 1 each time -> speed up
;
;    TPHOT: constant background or local background for each source
;
;  MOPHONGO:
;  + flux prior: see tphot_2.0 doc 4.3.5: -> add in quadrature to A and b in A x = b
;    aij = aij + 1/si^2  and Bi = Bi + fi/si^2, where is provided by user
;
;  + the cross correlation and polynomial interpolation: Hogg -> optimal centering
;    - positions -> first moment weighted
;    - then convolve elliptical gaussian within first moments and center fit w polynomial within a fraction of sigma
;
;  + in principle: because we have pixel convolved PSF
;    after building the model and convolving with the pixel convolved kernel
;    in principle.... we only have to *evaluate* at these positionsspare
;    -> check this!!!
;    according to Sampling Theorem we only have to sample low-res image at x2 the pixel size (do 2x to be sure)
;    seek the closest multiple within abs(25%) or the next one up
;
;  + so read in template image, process cut-out
;
;  + so that means if the low-resolution image is a well sampled PSF, we should not have to upsample it much further
;    that's why we want to work in ra dec
;
;  + when feeding it sextractor catalogs -> can let do the prior deblending for you
;
;  + @@@ PCA analysis: EM PCA can include missing data and has complexity (knp) rather than np^2
;    do stars on full image
;
;  - @@@ skysub:
;  + background: check that a reasonable background was always subtracted
;  + fit a bicubic spline with asymtric errors ??
;
; - @@@@ SWarp uses the Bron and Kerbosh algorithm (1973) based on FITS header information
; to estimate the maximum number of input frames that overlap and optimize the
; management of its internal buffers.
;
; AUTOPILOT:
; - @@@@ enable setting a max memory.
;
; - @@@@ crucial: make sure the image background is subtracted well. not under nor over subtracted
;
; @@@ to do:
;    write fit 2 results
;    write id's of objects used in fit
;  - write wrapper that reads a config file, runs a whole catalog, and writes a full catalog
;  - allow to give error image
;  - make option to provide only the 2 PSFs
;  - error estimate on aperture correct kernel?
; also write flux of aperture corrected tmpl

; comments fit residuals: color gradients
;  id 6878 doesnt really improve... -> blended and oversplit source.... 3x oversplit
; IRAC residual might be good diagnostic
; id 6913 in other cases it improves, but one is really fitting resolved colors....
; -> fit these direct with kernel !!!!
; can we parameterize model as a 'color gradient' ?
; 6945 much improved, but still big residual -> again, model color gradient directly ?
; .e.g we probably do not want to use these "improved" fits
; MOPHONGO::FIT_RESIDUALS [DEBUG] tweaking fit 6968 1200.7692 -> 405.28076 : 2.9628081 betteretter
; MOPHONGO::FIT_RESIDUALS [DEBUG] tweaking fit 6977 52.104965 -> 3.3358769 : 15.619571 b
; @@@id 7006 4.6638460 -> 0.35197556 : 13.250483 beautiful ex. merging galaxy with different colors
; @@@ IDEA model color gradient by ratio of phot / model
; tvs,(phot/model)[k4:3*k4,k4:3*k4],mm=[0.7,1.2]*1.
; tvs,(phot/modelt)[k4:3*k4,k4:3*k4],mm=[0.7,1.2]*1.
; 2 options: model in convolved space
; deconvolve onto HST resolution -> make HST-IRAC color map.... -> strong regulate!!!
; reconvolve and show fit.....


; this should go to separate class
;The Gaussian kernel (see equation 24) in the fixed-Gaussian polynomial
;centroiding is separable, and correlation of the kernel with an image
;of star can be performed exactly in no time. Therefore in terms of
;computational cost, this method is more efficient than the matched
;filter method in which the image of star is correlated with a PSF of
;arbitrary shape.

; @@@ Optimizations: 1 only consider part of kernel for fainter sources
; @@@ cache kernels, psfs
; @@@ rebuild fconvolve with faster FFTs. only FFT if needed
; @@@ determine by scaling IRAC_PSF to source peak flux -> cut err_pix/5.
; @@@ detimage should be called template image
; @@@ should be able to give multiple template images

pro mophongo::make_tmpl_thread_old, index, memseg, fit_snrlo_psf
   compile_opt static

   bin = self.param.fit_bin
; @@@@ can not have any self...
   ; link memory maps
   for i=0,memseg.length-1 do !null = execute(memseg[i]+' = shmvar("'+memseg[i]+'")')

   ; render kernel and template on ast_tmpl resolution = bin * ast_det resolution
   extast, headfits(self.fdet), ast_tmpl
   ast_tmpl.cd *= bin
   kern = mophongo.getkernel(1, 1, ast_kern=ast_kern, ast_out=ast_tmpl)
   npix_kern = bin*bin/total(kern^2)
   ; @@@  size of kernel in det pixel units -> note this should be in photometry image units

   !null = growthcurve(self.getpsf(1,1),rhalf=rhalf_det)
   !null = HISTOGRAM(segmap,min=1,rev=ri)
   kgrow = apermask(oddsize(round(rhalf_det*2)))
   dim = det.dim

   logger, 'Creating templates ', /info
   for i=0,index.length-1 do begin
      j = index[i]
      s = obj[j]
      print, '.', format='($,a)'

      iseg = cgReverseIndices(ri, s.id-1)  ; @@@ this indexing is not robust

      ; @@@ should read this from internal templates? not the image maps....
      ; so we can deal transparently with any model (blender, sersic fits)
      det_img = det[s.xmin:s.xmax,s.ymin:s.ymax]
      seg = segmap[s.xmin:s.xmax,s.ymin:s.ymax]

      ; grow mask of object and neigbors, keep grown pixels dominated by object
      knn = convol(seg ne s.id and seg ne 0, kgrow)
      kseg = convol(seg eq s.id, kgrow)
      kseg = kseg gt knn and kseg ne 0

      det_ivar = mean(detwht[iseg])               ; detection ivar
      s.eflux_model = sqrt(npix_kern / mean(photwht[iseg]) )  ; model error

      psf = mophongo.getpsf(s.x,s.y)

      tsz = det_img.dim
      psz = psf.dim
      xpeak = s.ipeak mod dim[0] - s.xmin
      ypeak = s.ipeak/dim[0] - s.ymin

      ; SNR in tmpl image segment, reject segment pixels < 0 -> these will be replaced by PSF wings
      iseg = where(kseg and det_img gt 0, complement=inoseg,/null)
      f_tmpl = total(det_img[iseg])
      e_tmpl = sqrt(iseg.length/det_ivar)

      ; @@@ need to make sure this works also for small psfs...
      ; place psf tile at highest peak
      psf_tile = extrac(psf,psz[0]/2-xpeak,psz[1]/2-ypeak,tsz[0],tsz[1])

      ; at low snr add in point source prior to tmpl in quadrature
      ; if det_img a empty map, then result is a point source prior
      ; @@@ note we are ignoring sub-pixel here.... probably ok
      if f_tmpl/e_tmpl lt 1.5*fit_snrlo_psf then $
         det_img[iseg] = sqrt(det_img[iseg]^2 + (e_tmpl*fit_snrlo_psf*psf_tile[iseg])^2)

      ; add PSF wings outside the segmap, normalized to flux in segment
      det_img[inoseg] = psf_tile[inoseg]*total(det_img[iseg])/total(psf_tile[iseg])
      det_img /= total(det_img)

      ksz = kern.dim * bin     ; treat kernel coordinates in tmpl pixel coordinates
      kloc = ( ksz/2 - tsz/2 ) > 0

      det_tile = extrac(det_img, -kloc[0], -kloc[1], ksz[0], ksz[1])
      if bin gt 1 then det_tile = rbin(det_tile, bin)  ; bin down tmpl just before convolution: ok, center good

      ; ast_tmpl takes care of pix scale / orientation
      kern = mophongo.getkernel(s.ra, s.dec, ast_out=ast_tmpl)
      s.tmpl = fconvolve(kern,det_tile)                        ; shift so ll pix divisible by bin

      s.xmin -= kloc[0]
      s.ymin -= kloc[1]
      s.xmax = s.xmin + ksz[0] - 1L
      s.ymax = s.ymin + ksz[1] - 1L
      s.dim = s.tmpl.dim * bin
stop

      if keyword_set(stopme) then begin
         tvs, kseg, pos=0
         tvs,det_img, pos=1
         tvs, s.tmpl, pos=2
         print, s.id, s.x, s.y, bin
         stopkey
      end

      ; store results
      obj[j] = s
   end
end


pro mophongo::make_tmpl_thread, index, memseg, fit_snrlo_psf
  ; compile_opt static

; @@@@ should condense and contain all position / size based transformations to src[0]

; @@@ simplify initialization, check binning vs no binning
   bin = self.param.fit_bin
   binfast = self.param.fit_fast ; calculate everything in binned ?
   if self.param.fit_interp eq 'cubic' then cubic=-0.5 else interp=1

   for i=0,memseg.length-1 do !null = execute(memseg[i]+' = shmvar("'+memseg[i]+'")')

   ; render kernel and template on ast_tmpl resolution = bin * ast_det resolution
   extast, headfits(self.fdet), ast_det
   extast, headfits(self.fdet), ast_tmpl
   ast_tmpl.cd *= bin

  ; note: kernel is pre-deconvolved for binning at scale bin, and interpolation (linear or cubic)
   kern = mophongo.getkernel(1, 1, ast_kern=ast_kern, ast_out=ast_tmpl)
   npix_kern = (ast_tmpl.cd[0]/ast_det.cd[0])^2/total(kern^2)

   gc = growthcurve(self.getpsf(1,1),rhalf=rhalf_det)
   h = HISTOGRAM(segmap,min=1,rev=ri)
   kgrow = apermask(oddsize(round(rhalf_det*2.0)))
   dim = det.dim
   fp=objects.flux_peak

; @@@ make sure it robustly determines where gc does not increase any more
   ftrunc = 1.0
   raper = range(2,202,30,/log)
   gckern= growthcurve( mophongo.getkernel(1, 1, ast_out=ast_tmpl), raper=raper)
   if ftrunc ge 1.00 then rlim = (objects[0].tmpl.dim)[0]*bin/2 $
      else rlim = interpol(raper, gckern, ftrunc < max(gckern))
   logger, 'truncating PSF to ftrunc=',ftrunc,' rlim = ',rlim

   logger, 'Creating templates ', /info
   for i=0,index.length-1 do begin
      j = index[i]
      s = objects[j]

    ;  iseg = cgReverseIndices(ri, s.id-1)  ; @@@ this indexing is not robust
       det_img = det[s.xmin:s.xmax,s.ymin:s.ymax]
       det_wht = detwht[s.xmin:s.xmax,s.ymin:s.ymax]
       phot_wht = photwht[s.xmin:s.xmax,s.ymin:s.ymax]
       seg = segmap[s.xmin:s.xmax,s.ymin:s.ymax]

      ; grow mask of object and neigbors, keep grown pixels dominated by object
      knn = convol(seg ne s.id and seg ne 0, kgrow)
      kseg = convol(seg eq s.id, kgrow)
      kseg = kseg gt knn and kseg ne 0
      iseg = where(kseg)  ; 1e-4

      det_ivar = mean(det_wht[iseg])               ; detection ivar
      s.eflux_model = sqrt(npix_kern / mean(phot_wht[iseg]) )  ; model error

      psf = mophongo.getpsf(s.x,s.y)   ; 1e-4

      hsz = det_img.dim
      psz = psf.dim
      xpeak = s.ipeak mod dim[0] - s.xmin
      ypeak = s.ipeak/dim[0] - s.ymin

      ; SNR in tmpl image segment, reject segment pixels < 0 -> these will be replaced by PSF wings
      iseg = where(kseg and det_img gt 0, complement=inoseg,/null)
      f_tmpl = total(det_img[iseg])
      e_tmpl = sqrt(iseg.length/det_ivar)

      ; @@@ need to make sure this works also for small psfs...
      ; place psf tile at highest peak
      psf_tile = extrac(psf,psz[0]/2-xpeak,psz[1]/2-ypeak,hsz[0],hsz[1])

      ; at low snr add in point source prior to tmpl in quadrature
      ; if det_img a empty map, then result is a point source prior
      ; @@@ note we are ignoring sub-pixel here.... probably ok
      if f_tmpl/e_tmpl lt 1.5*fit_snrlo_psf then $
         det_img[iseg] = sqrt(det_img[iseg]^2 + (e_tmpl*fit_snrlo_psf*psf_tile[iseg])^2)

      ; add PSF wings outside the segmap, normalized to flux in segment
      det_img[inoseg] = psf_tile[inoseg]*total(det_img[iseg])/total(psf_tile[iseg])
      det_img /= total(det_img)

      tsz = (s.tmpl.dim)[0]*bin

      if 0 then begin ; first convolve then bin
         ; kernel size in det coordinates -> lets truncate
         ; check if this works when det_img is > kernel size
         dsz = round(2*rlim+1)
         dloc = ( dsz/2 - hsz/2 ) > 0
         det_tile = extrac(det_img, -dloc[0], -dloc[1], dsz, dsz)
         kern = mophongo.getkernel(s.ra, s.dec, ast_out=ast_tmpl)
         kloc = dsz/2 - kern.dim/2
         kern_tile  = extrac(kern, -kloc[0], -kloc[1], dsz, dsz)
         ss = fconvolve(kern_tile,det_tile, pad=0)
         tloc =  tsz/2 - dsz/2
         s.tmpl =  rbin(extrac(ss, -tloc, -tloc, tsz, tsz),3)
         s.xmin -= (dloc + tloc)[0]
         s.ymin -= (dloc + tloc)[1]
      end else begin    ; first bin then convolve
         kloc = ( tsz/2 - hsz/2 ) > 0
         s.xmin -= kloc[0]
         s.ymin -= kloc[1]
         offx = (s.xmin - 1) mod bin
         offy = (s.ymin - 1) mod bin
         oxymin = [s.xmin,s.ymin]
         s.xmin -= offx      ;image so that xmin and ymin to be divisible by bin
         s.ymin -= offy       ; this aligns all binned patches to the same binned grid
; @@ if we are summing in binned coordinates, no extra smoothing -> so presmooth heren
; note @@ if we are doing any extra interpolation (e.g. shifting) then those convolutions need to be taken into account
       det_img = smooth(det_img,3)
         det_tile = extrac(det_img, -kloc[0]-offx, -kloc[1]-offy, tsz, tsz)
         ; check shift here   ; all ok!

         if bin gt 1 then det_tile = rbin(det_tile,3)
         kern = mophongo.getkernel(s.ra, s.dec, ast_out=ast_tmpl)
         s.tmpl = fconvolve(kern, det_tile, pad=0)
     end

      s.xmax = s.xmin + tsz - 1L
      s.ymax = s.ymin + tsz - 1L
      s.dim = s.tmpl.dim * bin

      ; store results
      objects[j] = s
      statusline, 'generating templates '+i.tostring()+'/'+(index.length).tostring()
   end
end

   ;   logger, j, ' SNR(tmpl,seg) = ',f_tmpl/e_tmpl
; convolution can be up by ~ > 100 x
; PSF/kern retrieval by # galaxies / grid cel, so at least > 10
; @@@ test centering w/bright pixel
; this is very slow... can optimize:
; - work in reduced resolution (e.g. binned to phot_psf_fwhm/5.0 -> x10 speed up for a 3x binning)
;   or bin to ~0.5 x phot pixel scale ~ 0.15
;   round((0.3/2.)/0.06) ->
; - buffer FFT PSF -> x2-3
; - analyse size of PSF brightess expected brightess of scaled PSF -> clip wings
;   e.g. central r<100 (19% of area) contain 95% of flux, versus full 405 x 405 stamp
;   -> 5x speed up for faint sources (e.g. for SNR < 10)
; @@ could calculate dynamically based on growthcurve, by requiring 1-phi(r<R) < fac/SNR(r<R)
; where fac = 0.3
; so for SNR < 10 wed discard < 5% of wings, and for SNR < 5 would be < 10%
; note: this flux is not "lost" we correct for it in any aperture corrections
; cap at a lower bound of SNR > 2.0 ; where it is a 30x speedup at the 15% clipping of wings


; @@@@ this needs to be simplified
; @@@@ e.g. by supplying instead location and desired pixscale and PA
; @@@@ put in structure including ra, dec, PA, pixscale (timeit, but shouldnt be slower)
; kern.img kern.ra, kern.dec kern
function mophongo::getkernel, ra, dec, filename=filename, cubic=cubic, x=x, y=y, $
                      ast_out=ast_out, ast_kern=ast_kern, getbasis=getbasis, $
                      gaussian=gaussian, bin=bin
   common mophongo_kernel_com, basis, coef, ast, gra, gdec, gx, gy, xc, yc, kernel, fkernel, kern_bin
   compile_opt static
   underflow_threshold = 1e-10

   ; load new kernel if requested
   if ~isa(kern) and (isa(filename) ? ~filename.equals(fkernel) : 0) then begin
      restore, filename           ; gra, gdec, hkern, basis, coef
      fkernel = filename
      ; assumes that grid is rectilinear with axis aligned with the PA of the basis functions
      ; rectilinear is saved as 2D, irregular list as 1D
      basis = kernel.basis
      coef = kernel.coef
      extast, hkern, ast
      ad2xy, gra, gdec, ast, gx, gy
      getrot, ast, pa, cdelt
      dim = long([sqrt((basis.dim)[0]), (basis.dim)[1]])
      coef = reform(coef, [(basis.dim)[1], gra.dim])
      logger, 'contains ', helpform('basis',basis),  helpform('coef',coef), ' PA=',pa,' pixscale=',cdelt[1]*3600.

      kern_bin = isa(kern_bin) ? kern_bin : 0
      logger, 'kern_bin', kern_bin
   end

   if isa(basis) and keyword_set(gaussian) then begin ; test PSF
      logger, 'loading gaussian test kernel ', gaussian, ' presmoothed by ', kern_bin
      bdim = basis.dim
      npix = sqrt((bdim)[0])
      basis = fltarr(npix,npix,bdim[1])
      basis[*,*,0] = mophongo.psf(npix=npix,fwhm=gaussian,/norm)
      basis = reform(basis,bdim)
   end

   if keyword_set(bin) then kern_bin = bin
   if arg_present(bin) then bin = kern_bin

   ; @@ shortcut: return cached kernel if position < 1/4 grid step
   ; may not be necessary anymore
   ;else if keyword_set(fast) then if isa(x) and isa(y) and isa(xc) and isa(yc) then $
   ;   if min(abs(xc-x))/(gx[1]-gx[0]) lt 0.25 and min(abs(yc-y))/(gy[0,1]-gy[0,0]) lt 0.25 then return, kernel

 ; adx2y is takes as much time as the kernel interpopation: 1e-4
   if keyword_set(ra) and keyword_set(dec) then ad2xy, ra, dec, ast, x, y
   if not keyword_set(x) then x = gx      ; build full grid if coordinates not given
   if not keyword_set(y) then y = gy

   ksz = sqrt((basis.dim)[0])
   nb = (basis.dim)[1]
   xmin = min(gx[*,0])
   xmax = max(gx[*,0])
   ymin = min(gy[0,*])
   ymax = max(gy[0,*])
   nx = (gx.dim)[0]
   ny = (gy.dim)[1]

   if keyword_set(getbasis) then begin ; @@@ ugly, should just fill it with convenient structure for basis...
      len = nb
      kernel = reform(basis, ksz, ksz, len)
   end else begin
      len =  n_elements(x)
      kernel = fltarr(ksz, ksz, len)
      ; @@@ interpolation is fast, only PCA coeficients, so we can also support irregular grids
      ; @@@ check if interpolation correct.. edge effects/pixel center etc..  use poly_2D ?
      ; @@@ i dont think these coordinates are quite right? it says ok in getpsf.
      ; the wcs / fits standard assumed center of pixel
      for i=0,len-1 do begin   ; coordinates ok, checked!  max(spx) works because image coordinates start at 0
         ix = 1.0*(nx-1)*(x[i]-xmin)/(xmax-xmin) > (-0.5) < (nx-0.5) ; normalized index grid for interpolate
         iy = 1.0*(ny-1)*(y[i]-ymin)/(ymax-ymin) > (-0.5) < (nx-0.5)

         cc =  interpolate(coef, ix, iy, cubic=cubic)   ; extrapolation picks nearest value it seems
         kernel[0,0,i] = reform( basis # cc, ksz, ksz)
         if keyword_set(normalize) then kernel[*,*,i] /= total(kernel[*,*,i])
      end
      xc = x
      yc = y
   end

   if arg_present(ast_kern) then ast_kern = ast

  ; @@@ consolidate warp_image and rebin, then wrap with astro wcs header
  ; if angle or pixel scale in ast_out astrometry differnt, warp result
  ; @@@ clean this up
   if keyword_set(ast_out) then begin
      getrot, ast, pa, cdelt
      getrot, ast_out, pa_out, cdelt_out
      rscl = cdelt[1]/cdelt_out[1]
      tsz_out = oddsize(round(rscl*ksz),div=3)

      if abs(pa-pa_out) gt 1e-3 or abs(rscl-1) gt 1e-3 and rscl gt 1.0 then begin ; upsampling

          kernel_out = fltarr(tsz_out,tsz_out,len)

         ; @@@ check centering and speed with congrid? see congrid.pro seems to
         ; @@@ add an outsize to warp_image
         ; @@@ if cleanup warp image including an outsize and optional flux conserve
         for j=0,len-1 do $       ; cubic interpolation  is needed, even for oversampled kernels
            kernel_out[0,0,j] = warp_image(kernel[*,*,j], 0.0, rscl, (ksz-1)/2., (ksz-1)/2., $
                              dimx=tsz_out, dimy=tsz_out, cubic=-0.5, missing=0.0) / rscl^2

; k=warp_image(extrac(kernel[*,*,j],0,0,tsz_out,tsz_out), 0.0, rscl, (ksz-1)/2., (ksz-1)/2., cubic=-0.5, missing=0.0) / rscl^2
; k1=warp_image(kernel[*,*,j], 0.0, rscl, (ksz-1)/2., (ksz-1)/2., dimx=tsz_out, dimy=tsz_out, cubic=-0.5, missing=0.0) / rscl^2
          return, kernel_out * (kernel_out gt underflow_threshold)
      end
      if abs(pa-pa_out) gt 1e-3 or abs(rscl-1) gt 1e-3 and rscl lt 1.0 then begin ; dowsampling
         if abs(1.0/rscl-round(1.0/rscl)) gt 1e-3 then message, 'non-integer downsampling not supported'
         kernel_out = fltarr(tsz_out,tsz_out,len)
         ;   cubic interpolation  is needed, even for oversampled kernels
         for j=0,len-1 do kernel_out[0,0,j] = rbin(kernel[*,*,j],round(1.0/rscl))
         return, kernel_out
      end
   end

   return, kernel * (kernel gt underflow_threshold)
end

function mophongo::getpsf, x, y, filename=filename, verbose=verbose, normalize=normalize,$
                  gaussian=gaussian
   common mophongo_psf_com, basis, spx, spy, spci, pscl, xc, yc, psf, fpsf
   compile_opt static

   underflow_threshold = 1e-10
   ; spatial variation interpol can be linear interpol too
   ; -> so expose interface with linear default and cubic/nearest  as options

   ; load new PSF model from disk
   if ~isa(basis) or isa(filename) then if ~filename.equals(fpsf) then begin
      logger, 'loading ', filename
      restore, filename
      fpsf = filename
   end

   if isa(basis) and keyword_set(gaussian) then begin ; test PSF
      logger, 'loading gaussian test psf '
      bdim = basis.dim
      npix = sqrt((bdim)[0])
      basis = fltarr(npix,npix,bdim[1])
      basis[*,*,0] = mophongo.psf(npix=npix,fwhm=gaussian,/norm)
      basis = reform(basis,bdim)
   end

   ; reuse the same psf if the requested PSF is within 0.5 intervals of the grid coordinates
 ;  if isa(x) and isa(y) then begin

   if (size(basis))[0] eq 1 then nb = 1 else nb = (size(basis,/dim))[1]
   tsz = long(sqrt((size(basis,/dim))[0]))   ; @@@ check should take existing grid

   ; @@@ rename spx/spy to gx/gy
   if not keyword_set(x) then x = spx
   if not keyword_set(y) then y = spy

   len =  n_elements(x)
   psf = fltarr([tsz,tsz,len])
   cc = fltarr(nb)
   mx = max(spx)
   my = max(spy)
   sz=size(spx,/dim)
   for i=0,len-1 do begin   ; coordinates ok, checked!  max(spx) works because image coordinates start at 0
      cc = interpolate(spci, 1.*(sz[0]-1)*x[i]/mx, 1.*(sz[1]-1)*y[i]/my)
      cpsf = reform( basis # cc, tsz, tsz)
      if keyword_set(normalize) then psf[0,0,i] = cpsf/total(cpsf) else psf[0,0,i] = cpsf
   end

   !null = check_math(mask=32)
   return, psf * (psf gt underflow_threshold)
end

; nx x ny x nstar cube
; weight nstar list of weights
function mophongo::pca, cube, basis, max_basis=max_basis, max_var=max_var, weight=weight, $
                  rwindow=rwindow, rthreshold=rthreshold, pca_cube=pca_cube, tol=tol

   compile_opt idl2, static

   nstar = (cube.dim)[2]
   tsz = (cube.dim)[0]
   if not keyword_set(tol) then tol = 1e-8
	if n_elements(max_basis) eq 0 then max_basis = ceil(nstar^0.7-0.5)
	max_basis = max_basis < (nstar-1) > 0

   ; weighting with inverse variance (or weaker power if systematics driven)
   imcombine, cube, basis, weight=weight

   logger, 'using ',max_basis+1, ' basis functions', /info

   basis[where(finite(basis) eq 0)] = 0
 	basis /= total(basis,/nan)
   coef =  replicate(1.0,1,nstar)

   ; @@@ TODO use EMPCA or some weighted PCA throughout
   ; @@@ only let if perform on inner part, use average to determine outer wing
   ; if more than 0 basis functions do PCA analysis. Otherwise just use average
   if max_basis gt 0 then begin
      ; @@@ note: in case of 2 stars, the 2nd PCA component is always == 0! doh

      ; subtract mean PSF
      sz = size(rcube,/dim)
      rcube = cube - rebin(basis,tsz,tsz,nstar)
      rcube[where(finite(rcube) eq 0,/null)] = 0.0

      rcomp = pcomp(transpose(reform(rcube,tsz*tsz,nstar)), coeff=coeff, /covar, eigen=ev, var=var, /double)

      if ~keyword_set(max_var) then max_var = 1.0
      cvar = total(var,/cum)
      cvar /= max(cvar)
      max_basis = (max(where(cvar lt max_var))+1) > 1 < (nstar-1)

      logger, 'updating to ',max_basis+1, ' basis functions based on variance ', /info

      pca_basis_full = transpose(rcomp)

      ; @@@ hack: sigmoid window function for basis components... with soft cut at rthreshold
      ; @@@ pca components at large radii are just noise... -> use weighted PCA
      if keyword_set(rwindow) then begin
         if not keyword_set(rthreshold) then rthresh = tsz/5.0
         sm = lambda(x,m,s: 1.0/(1+exp(-(x-m)/s)))     ; sigmoid window
         !null = apermask(tsz,d=rr)
         !null = growthcurve(cube[*,*,0],raper=raper,rhalf=rhalf)
         ww = 1.0-sm(rr, rthresh, 1.5*rhalf*2 < tsz/15.0)
         for i=0,(pca_basis_full.dim)[1]-1 do pca_basis_full[*,i] *= ww
         ; @@@ todo: since I changed the basis slightly
         ; @@@ I should rederive the coefficients by projecting stars onto new windowed basis
      end

      pca_basis = pca_basis_full[*,0:max_basis-1]

      if max(ev) eq 0 then ev=[1,1]  ; add this in case star = 1
      pca_coef = ( transpose(coeff/rebin(ev,nstar,nstar)) )[0:max_basis-1,*]
   end

   if arg_present(pca_cube) then begin
      pca_cube = fltarr(cube.dim)
      for i=0,nstar-1 do  pca_cube[0,0,i] = basis + (isa(pca_coef) ? reform((pca_coef[*,i] ## pca_basis),tsz,tsz) : 0.0)
   end
;	if isa(pca_basis) then basis = [[[basis]],[[reform(pca_basis,tsz,tsz,max_basis)]]]
	if isa(pca_basis) then basis = [[reform(basis,tsz*tsz)], [pca_basis]]
   if isa(pca_coef) then coef = [coef,pca_coef]

;	help, basis,pca_coef
	return,  { basis:float(basis), coef:float(coef) }
end


; @@@ windowed FFT deconv is really fast, but breaks on marginally sampled kernels
; @@@ others essentially break too (e.g. iterative ML), but more gracefully
; @@@ would it help to simple oversample image by x2 ?
; get kernel to convolve img1 to img2
; basis must be in fft(basis_i)
; img1 and img2 must have same dimensions and square
; coeff returns best fitting coefficients
pro mophongo::decon_pix, img1, img2, basis, verbose=verbose

  if not keyword_set(cthresh) then cthresh=0.0
  if not keyword_set(ll_method) then ll_method = 3
  s = (size(img1))[1]
  len = s*s
  nb=(size(basis))[3]

; faster in real space
  if isa(basis,/float) then begin
       lax = fltarr(nb,len)

       for i=0,nb-1 do lax[i,*] = fconvolve(basis[*,*,i],img1)

       kern = la_least_squares(lax, img2[*], residual=lares, method=ll_method) ; get minimum norm solutio
  end
end

function mophongo::getirac_basis
   common mophongo_aor_com, mpsf, hpsf, map, hmap, current_psf, center_box

   adxy, hmap, ra, dec, x, y
   ix = round(x)
   iy = round(y)

   sz2 = ((mpsf.dim)[0]-1.0)/2.0
   rscl = pixscale(hpsf)/pixscl
   tsz = oddsize(round(rscl*(mpsf.dim)[0]),div=3)

   ww =  map[ix,iy,0,*]     ; could interpolate for finer grid result
   wpa =  map[ix,iy,1,*]    ;
   wh = im_hist1d(wpa, ww, binsize=2, obin=xh)

 ; get most prominent directions, put into basis vector
   dif = convol(wh,[-1,2,-1])
   i =  where(dif gt max(dif)/5.0)

   pa_list = xh[i]
   psf_basis = fltarr(n_elements(pa_list),tsz,tsz)

   foreach a, pa_list, j do $
      psf_basis[j,*,*] = warp_image(extrac(mpsf,0,0,tsz,tsz), a + pa, rscl, sz2, sz2, cubic=-0.5, missing=0.0)

   return, psf_basis
end

; merge with make model
function mophongo::make_model_fast, src, scale,  index=index, id=id, inn=inn, clean=clean, residual=residual, $
   distance=distance, detection=detection, phot=phot, winx=winx, winy=winy, outsize=outsize, stopme=stopme, full=full
   if self.param.fit_interp eq 'cubic' then cubic=-0.5 else interp=1

    inn = self.overlap(src, index, id=id, distance=distance)

   bin = self.param.fit_bin
   model = fltarr((*self.photimg).dim/bin)
   tsz = ((src[0].tmpl).dim)[0]

   xmin  =  (src.xmin-1)/bin
   ymin  =  (src.ymin-1)/bin

   foreach i, inn do begin
      if scale[i] eq 0.0 then continue
      model[xmin[i]:xmin[i]+tsz-1,ymin[i]:ymin[i]+tsz-1] +=  src[i].tmpl*scale[i]
      if i mod 2 then statusline, 'adding to model '+i.tostring()+'/'+(inn.length).tostring()
   end
  if keyword_set(full) then model = shift(rbin(model,bin,/expand,interp=interp,cubic=cubic),1,1)
  if keyword_set(stopme) then stop
  return, model
end

function mophongo::make_model, src, scale,  index=index, id=id, inn=inn, clean=clean, residual=residual, $
   distance=distance, detection=detection, phot=phot, winx=winx, winy=winy, outsize=outsize, $
   cube=cube, full=full, showme=showme, stopme=stopme

   if self.param.fit_interp eq 'cubic' then cubic=-0.5 else interp=1
   bwinx = [1#src.xmin, 1#src.xmax]
   bwiny = [1#src.ymin, 1#src.ymax]
   bin = self.param.fit_bin
   w =  (src[0].tmpl.dim)[0]*bin

   if bin gt 1 and self.param.fit_fast then begin  ; build in  binned coordinates
      model = fltarr((shmvar('model')).dim/bin)
      w = w/bin
      xmin = (src.xmin-1.0)/bin
      ymin = (src.ymin-1.0)/bin
      bwinx = (bwinx-rebin([1,bin],2,bwinx.length))/bin
      bwiny = (bwiny-rebin([1,bin],2,bwiny.length))/bin
      if arg_present(residual) then phot = rbin(shift(*self.photimg,-1,-1),3) else phot=shmvar('phot')
      if arg_present(detection) then det = rbin(shift(*self.detimg,-1,-1),3) else det=shmvar('det')
   end

   ; list of all prior elements overlapping the current tile
   inn = self.overlap(src, index, id=id, distance=distance)

   if n_elements(id) eq 1 or n_elements(index) eq 1 then begin
      model = fltarr(w,w)
      winx = bwinx[0:1,index]
      winy = bwiny[0:1,index]
   end else begin
      if bin gt 1 and self.param.fit_fast then model = fltarr((shmvar('model')).dim/bin) $
         else model = shmvar('model') * 0.0
      winx = [0,(model.dim)[0]-1]
      winy = [0,(model.dim)[1]-1]
   end

   if keyword_set(outsize) then oloc = outsize[0]/2-model.dim/2
   if arg_present(cube) then cube=fltarr([model.dim,inn.length])

   foreach i, inn, ii do begin
      if scale[i] eq 0.0 then continue

      rect_intersect, winx, winy, bwinx[0:1,i], bwiny[0:1,i], ox, oy, omx, omy, oix, oiy, is_empty=is_empty

      if self.param.fit_fast and bin gt 1 then begin  ; @@@ NB: doesnt deal with edge effects
         if keyword_set(cube) then cube[omx[0]:omx[1],omy[0]:omy[1],ii] =  src[i].tmpl[oix[0]:oix[1], oiy[0]:oiy[1]]*scale[i]
         model[omx[0]:omx[1],omy[0]:omy[1]] +=  src[i].tmpl[oix[0]:oix[1], oiy[0]:oiy[1]]*scale[i]
      end else begin
         if bin eq 1 then tmpl = src[i].tmpl $
            else tmpl = congrid(src[i].tmpl, wx, wy, cubic=cubic, interp=interp, /center)
         model[omx[0]:omx[1],omy[0]:omy[1]] +=  tmpl[oix[0]:oix[1], oiy[0]:oiy[1]]*(scale[i]/bin^2)
      end
   end

   if keyword_set(outsize) then begin
      model = extrac(model, -oloc[0], -oloc[1], outsize[0], outsize[0])
      if keyword_set(cube) then cube = extrac(reform(cube,[w,w,inn.length]), -oloc[0], -oloc[1], 0, outsize[0], outsize[0], inn.length)
      winx = winx[0] - oloc[0] + [0,outsize[0]-1]
      winy = winy[0] - oloc[1] + [0,outsize[0]-1]
   end

   if arg_present(residual) then residual = phot[winx[0]:winx[1],winy[0]:winy[1]] - model
   if arg_present(detection) then detection = det[winx[0]:winx[1],winy[0]:winy[1]]

   ; @@@ mostly debugging as inflated model will be too smooth due to binning convolutions
   if bin gt 1 and self.param.fit_fast and keyword_set(full) then model = rbin(model,/expand,3)

   if keyword_set(showme) then begin
      s = mad(model,bad=0,/sample)*100
      cgerase
      cgimage, phot[winx[0]:winx[1],winy[0]:winy[1]], /keep, layout=[2,2,1], /stretch, $
               minv=-s, maxv=s, /axes, xr=winx+[-0.5,0.5], yr=winy+[-0.5,0.5]
      if n_elements(inn) gt 0 then cgplots, src[inn].x, src[inn].y, psym=9,color='green', thick=1, symsize=2
      if n_elements(index) gt 0 then cgplots, src[index].x, src[index].y, psym=9,color='red', thick=2, symsize=2
      cgplots, src.x, src.y, psym=3, color='yellow', thick=1, symsize=1

      cgimage, model, /keep, layout=[2,2,3], /stretch, minv=-s, maxv=s, /axes, xr=winx+[-0.5,0.5], yr=winy+[-0.5,0.5]
      if n_elements(index) gt 0 then cgplots, src[index].x, src[index].y, psym=9,color='red', thick=1, symsize=2

      if arg_present(detection) then begin
         sd = 10*mad(detection,bad=0)
         cgimage, detection, /keep, layout=[2,2,2], /stretch, minv=-sd, maxv=sd, /axes, xr=winx+[-0.5,0.5], yr=winy+[-0.5,0.5]
         if n_elements(index) gt 0 then cgplots, src[index].x, src[index].y, psym=9,color='red', thick=1, symsize=2
      end

      if isa(residual) then begin
         cgimage, residual, /keep, layout=[2,2,4], /stretch, minv=-s, maxv=s, /axes, xr=winx+[-0.5,0.5], yr=winy+[-0.5,0.5]
         if n_elements(index) gt 0 then cgplots, src[index].x, src[index].y, psym=9,color='red', thick=1, symsize=2
      end
   end

   return, model
end

; update RHS AT dot b
; @@@ check for diagonal elements that are ~ 0
function mophongo::make_RHS, src, cubic=cubic, interp=interp
   compile_opt idl2

   if not keyword_set(cubic) and n_elements(interp) eq 0 then cubic=-0.5

   xmin = src.xmin
   xmax = src.xmax
   ymin = src.ymin
   ymax = src.ymax
   wx = xmax-xmin+1
   wy = ymax-ymin+1
   wxy = src[0].tmpl
   len = src.length
   atb = dblarr(len)
   bin = self.param.fit_bin
   faper, *self.photwht, round(src.x), round(src.y), self.param.rhalf_phot/3.0, ww, os=1, /mean
   phot = shmvar('phot')

   for j=0L,len-1 do begin
      if bin eq 1 then img_j = src[j].tmpl $  ; A * w * b
         else img_j = congrid(src[j].tmpl, wx[0], wy[0], cubic=cubic, interp=interp, /center)

         b = phot[xmin[j]:xmax[j], ymin[j]:ymax[j]]
         if bin gt 1 then b = smooth(b,bin+1)     ; smooth for binning just as models

       atb[j] = total(img_j * b) * (ww[j] / bin^2)
       statusline,'Updating RHS '+j.tostring()+'/'+len.tostring()
   end

   return, atb
end


;@@@@ skicit learn 2.6
;@@@@This is why it makes sense to estimate a sparse precision matrix: by learning independence ;
; relations from the data, the estimation of the covariance matrix is better conditioned. This is known as covariance selection.
;
; normal matrix of AT.A = AT.b
pro mophongo::make_normal, src, ata, atb, append=append, update=update, background=background, $
                     weight_gaussian=weight_gaussian, noisefloor=noisefloor, sortbright=sortbright,$
                      stopme=stopme, verbose=verbose
   compile_opt idl2

   if self.param.fit_interp eq 'cubic' then cubic=-0.5 else interp=1

   if n_elements(update) eq 0 then update = 0B
   if n_elements(append) eq 0 then append = 0B
   sparse = python.import('scipy.sparse')
   python.run, 'import numpy as np'

  ; cut bloat here
   bin = self.param.fit_bin
   dim = src.dim                ; dimension of image stamp in det coordinates
   buf = 3L                     ; minimum overlap in x and y between src i and each j
   len = src.length
   xmin = src.xmin
   ymin = src.ymin
   xmax = src.xmax
   ymax = src.ymax
   wx = xmax-xmin + 1
   wy = ymax-ymin + 1
   bx = src.x
   by = src.y
   rlim = max(wx>wy)

   ;  update, append, or initiate a sparse matrix
   if isa(ata) and append then begin   ; append to existing ata: 1) extend array, 2) when adding elements count backwards
       python.a = ata.tocoo()        ; @@@ following should be ok, but test
       python.run,'a = sparse.coo_matrix((np.append(a.data,0.0), (np.append(a.row,'+strn(len)+'),  np.append(a.col,'+strn(len)+'))))'
       ata = (python.ata).tolil()
       index = lindgen(len,start=(ata.dim)[0])
   end else if isa(ata) and update then begin
      python.ata = ata.tolil()
      index = update
   end else begin  ; create new     ;   if isa(background) then background=0.0
      Python.Run, 'ata = sparse.lil_matrix(('+strn(len)+','+strn(len)+'))'
      ata = Python.ata
      atb = dblarr(len)
      index = lindgen(len)
   end

   ; @@@@ assumes phot image is on det scale; @@@ check: if phot not transformed to det then x,y positions wrong -> ra,dec
   fpeak = (*self.photimg)[round(bx),round(by)]
   faper, *self.photwht , bx, by, self.param.rhalf_phot/3.0, ww, os=1, /mean

  ; precalculate inproduct of PSF as a function of separation (used later to predict sparsity cut off)
   extast, headfits(self.fdet), adet   ; @@@ could do quicker, in binned scale and multiply by bin
   tt = rbin(self.getkernel(median(src.ra), median(src.ra), ast_out=adet))
   for i=0,(tt.dim)[0]-1 do ff = append(ff, total(tt*imshift(tt,i*0.707,i*0.707),/nan))

   ; cutting inproduct on radius (when below noise floor): calculate brightest first
   ; so always uses largest rlim_snr and overlap with fainter source is always calculated
   if keyword_set(sortbright) or isa(noisefloor) then index = index[reverse(sort(fpeak[index]))]
   rtile = (wx[index] > wy[index])/2.
   bx = bx[index]
   by = by[index]

   if bin gt 1 and self.param.fit_fast then begin  ; inproduct in binned coordinates
       ; @@@@ hmmm need to offset phot by -1,-1 ???
      phot = rbin(shift(*self.photimg,-1,-1),bin)  ; note... this is now a local copy
      xmin = (xmin-1.0)/bin
      ymin = (ymin-1.0)/bin
      wx = wx/bin
      wy = wy/bin
   end else phot = shmvar('phot')

   ; build sparse matrix AT * A, row by row, build AT 8 b
   foreach j, index, jj do begin

      ; img_j = src[j].tmpl * ww[j]  ;  AT * ivar  ; note postpone ww and bin^2 scaling until total()
      if bin eq 1 or self.param.fit_fast then img_j = src[j].tmpl else $
         img_j = congrid(src[j].tmpl, wx[0], wy[0], cubic=cubic, interp=interp, /center)

      ; AT * b * ivar
      if arg_present(atb) then begin
         b = phot[xmin[j]:xmin[j]+wx[j]-1,ymin[j]:ymin[j]+wy[j]-1]
         atb[j] = total(img_j * b) * ww[j] / bin^2
 ;        if isa(background) then background += total(b)*ww[j]
      end

      ; only consider sources to a radius where its PSF profile is > noisefloor
      if keyword_set(noisefloor) then rlim = interpol([0:ff.length-1],(fpeak[j]*sqrt(ww[j])>1)*sqrt(ff/ff[0]),noisefloor)

      ; check for overlapping bases, cull on distance between j and i
      ; - default: built full matrix in incremental mode (default)
      ; - update: consider full row
      ; - append: consider all preceding (in enlarged matrix, so count until index)
      if update then ij = [0:len-1] else if append then ij = [0:jj] else ij = [jj:len-1]
      sij = sqrt( (bx[jj] - bx[ij])^2 + (by[jj] - by[ij])^2 )
      icol = where(sij lt (rtile[jj]+rtile[ij]-buf) < rlim, ncol, /null)

      ; calculate AT dot A cross terms for every overlapping src i,j on row j
      if keyword_set(append) or keyword_set(update) then irow = index[icol] else irow = index[jj + icol]

      ata_row = fltarr(ncol)        ; collect dot products in sparse row
      for k=0L,ncol-1 do begin
          i = irow[k]
         ; @@@ push this to overlap rect?
         ; overlap in local src j
          jx1 = (xmin[i] - xmin[j]) > 0 < (wx[j] - 1)
          jy1 = (ymin[i] - ymin[j]) > 0 < (wy[j] - 1)
          jx2 = (xmax[i] - xmin[j]) > 0 < (wx[j] - 1)
          jy2 = (ymax[i] - ymin[j]) > 0 < (wy[j] - 1)
          ; overlap in local src i
          ix1 = (xmin[j] - xmin[i]) > 0 < (wx[i] - 1)
          iy1 = (ymin[j] - ymin[i]) > 0 < (wy[i] - 1)
          ix2 = (xmax[j] - xmin[i]) > 0 < (wx[i] - 1)
          iy2 = (ymax[j] - ymin[i]) > 0 < (wy[i] - 1)

         if bin eq 1 then imi = src[irow[k]].tmpl else begin
            if self.param.fit_fast then $
               imi = extrac(src[i].tmpl, xmin[j]-xmin[i], ymin[j]-ymin[i], wx[j], wy[j]) $
            else $
               imi = congrid(src[irow[k]].tmpl, dim[0], dim[1], cubic=cubic, interp=interp, /center)
         end

       ; dot product imj * imi * ww on overlap = AT * A * ivar ; bin^4 = flux scaling for imj and imi
       if self.param.fit_fast then  ata_row[k] = total(img_j*imi) * (ww[j]/bin^2) else $
          ata_row[k] = total(img_j[jx1:jx2, jy1:jy2] * imi[ix1:ix2,iy1:iy2]) * (ww[j]/bin^4)
     end

      ; threshold always > 0.0
      ata_row[where(ata_row lt max(ata_row)*self.param.fit_sparse_threshold,nz,/null)] = 0.0

      if keyword_set(verbose) then logger, jj, src[j].id, rlim, ncol,  ncol-nz, cubic

      ; put indexed row in sparse matrix
      ; index i is offset from diagional j if building upper triangle of full matrix
      python.jpicol = irow
      python.ata_row = ata_row
      Python.Run, 'ata['+j.tostring()+',jpicol] = ata_row'

      ; update: also put in column to make symmetric
      if keyword_set(update) then begin
          python.ata_row = reform(ata_row,1,ncol)
          Python.Run, 'ata[jpicol,'+j.tostring()+'] = ata_row'
      end

      statusline, 'building normal equations '+jj.tostring()+'/'+len.tostring()
      !null = check_math(mask=32)
   end

   ata = Python.ata
   ata = ata.tocsr()
   if keyword_set(stopme) then stop
   if keyword_set(update) then return                    ; if update were already symmetric
   if keyword_set(append) then ata = ata.tril()          ; else make symmetric
   ata = ata + ata.transpose() - sparse.diags(ata.diagonal())
end

; normal matrix of AT.A = AT.b
; update existing normal matrix with prior constraints
pro mophongo::regularize_normal, ata, atb, fprior, eprior, index=index, stopme=stopme
   compile_opt idl2

   if not keyword_set(index) then index = lindgen(atb.length)

   ata = ata.tocoo()

   d = ata.diagonal()
   d[index] += 1.0/eprior^2
   !null = ata.setdiag(d)

   atb[index] += fprior / eprior^2

   ata = ata.tocsr()

   if keyword_set(stopme) then stop
end

; normal matrix of AT.A = AT.b
; update existing normal matrix with prior constraints
function mophongo::covariance, ata, scale, threshold=threshold, stopme=stopme
   compile_opt idl2

   if not keyword_set(threshold) then threshold=1e-5

   a = ata.tocoo()
   aa=a.todense()
   aai = invert(aa)

;   plot, sqrt(diagonal(aai))
;   nn = total(aa)
;   print, 1.0*n_elements(where(aa ne 0))/n_elements(aa)
;   aa -= rebin(mean(aa,dim=1),dim)
;   c = aa # aa / nn^2
;   plot, c.diagonal()

   dim = a.shape.toarray()
   nn = dim[0]-1

; this is not right, because it is not ever using the zero components
   am = a.mean(0)
   data = a.data
   for i=0,dim[0]-1 do data[where(a.row eq i,n)] -= am[i]*dim[0]/n
   a.data = data

   a = a.tocsr()
   a = a.dot(a) / (dim[0]-1)

   if keyword_set(stopme) then stop

   a = a.tocoo()
   dm = a.diagonal()
   data = a.data
   for i=0,dim[0]-1 do begin &$
      j=where(a.row eq i) &$
      data[j] *= abs(data[j]) gt dm[i]*threshold &$
   end
   a.data = data

   return, a.multiply(a gt dm*self.param.fit_sparse_threshold)
end
;    # the correlation coefficients are given by
;    # C_{i,j} / sqrt(C_{i} * C_{j})
;    d = np.diag(C)
;    coeffs = C / np.sqrt(np.outer(d, d))
;
;If your curve fit is unconstrained and your residual has uniform variance s2, then a common approximation to the covariance matrix of the parameters is
; Cov=inv(J'*J)*s2
;where J is the Jacobian of the residual at the solution. Both LSQCURVEFIT and LSQNONLIN return the Jacobian as an optional output argument
;I saw that CovB = inv(J'*J)*MSE in a MATLAB documentation here at http://www.mathworks.com/help/stats/nlinfit.html
 ;http://stats.stackexchange.com/questions/231868/relation-between-covariance-matrix-and-jacobian-in-nonlinear-least-squares
; http://stats.stackexchange.com/questions/10795/how-to-interpret-an-inverse-covariance-or-precision-matrix
;http://stats.stackexchange.com/questions/73463/what-does-the-inverse-of-covariance-matrix-say-about-data-intuitively
;     cov= inv(ATwwA)
;  standard approximation to the Hessian of a nonlinear least squares problem used by Gauss-Newton and Levenberg-Marquardt algorithm
;Consider the nonlinear least squares problem: minimize 1/2r(x)Tr(x)
;. Let JJ = Jacobian of r(x). The Hessian of the objective = JTJ+JTJ
; higher order terms. The Gauss-Newton or Levenberg-Marquardt approximation is to ignore the higher order terms, and approximate the Hessian as JTJ
; . This approximation for the Hessian is what is used in the formula CovB = inv(J'*J)*MSE in MATLAB's nlinfit.
;The higher order terms are close to zero at the solution if the residuals r(x) are close to zero. If the residuals are large at the solution, the approximation may be very inaccurate. See the first 7 slides of https://www8.cs.umu.se/kurser/5DA001/HT07/lectures/lsq-handouts.pdf . There is also mention, with less detail provided, at https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm.


function mophongo::solve, src, ata, atb, model=model, residual=residual, fsig=fsig, fres=fres, $
                   regul_neg=regul_neg, regul_res=regul_res, stopme=stopme
   if not keyword_set(regul_neg) then regul_neg = 0
   if not keyword_set(regul_res) then regul_res = 0
   thresh = self.param.fit_neg_threshold
   bin = self.param.fit_bin

   la = python.import('scipy.sparse.linalg')
   scale = (la.cg(ata.tocsr(), atb, tol=self.param.fit_tol))[0]

; ----- regularize negativity fits ------------
   logger, 'regularize negative fits ', /info
   for i=0,regul_neg-1 do begin
      ibad = where(scale/src.eflux_model lt thresh, nbad)
      if nbad eq 0 then continue
      self.regularize_normal, ata, atb, fltarr(ibad.length), src[ibad].eflux_model, index=ibad
      scale = (la.cg(ata, atb,tol=self.param.fit_tol))[0]
      logger, i, nbad, ' regul neg '
   end

   if keyword_set(regul_res) then begin

      model = self.make_model(src, scale, residual=residual)

      faper, 1.0/self.photwht , src.x, src.y, self.param.rhalf_phot/2.0, fsig, os=1
      fsig = sqrt(fsig)
      x = src.x
      y = src.y

; @@@ test this on fast mode
     if self.param.fit_fast and bin gt 1 then begin
        x = (src.x-1)/bin
        y = (src.y-1)/bin
        pw = rbin(shift(*self.photwht,-1,-1),3)
        faper, 1.0/pw,  x, y, self.param.rhalf_phot/2.0/bin, fsigb, os=1
        fsigb = sqrt(fsigb)*bin^2
      end

      for i=0,regul_res-1 do begin
         if i eq 0 then logger, 'regularize fits with strong residuals', /info

         snr = scale/src.eflux_model
         faper, residual, x, y, self.param.rhalf_phot/2.0/bin, fres, os=1

; @@@ test this on fast mode
         ibad = where(fres/fsig lt thresh or (snr lt thresh and fres/fsig gt -thresh), nbad, complement=iok)

         fprior = (scale[ibad] + 2.0*(fres/fsig)[ibad]*src[ibad].eflux_model ) > 0.0
         eprior = src[ibad].eflux_model

         self.regularize_normal, ata, atb, fprior, eprior, index=ibad

         scale= (la.cg(ata, atb, tol=self.param.fit_tol))[0] > (thresh*src.eflux_model)

         model = self.make_model(src, scale > ((i eq regul_res-1) ? 0.0 : (-1e30)), residual=residual)
         logger, i, nbad, ' regul res '
      end
   end

  report_memory
  return, scale
end

; test if also can be fitted with PCA PSF residuals
; then provides a way of mapping PSF at higher spatial resolution
; ------------- tweak fits of brightest objects with large residuals
; add additional templates for the brightest sources to model residual:
; e.g., gradients, nuclear activity, or small shifts, size
function mophongo::fit_residuals, src, scale, ifix, stopme=stopme, interp=interp, cubic=cubic
   ; common mophongo_kernel_com, basis, coef, ast, gra, gdec, gx, gy, xc, yc, kernel, fkernel

   ifix = reverse(ifix[sort(scale[ifix]/src[ifix].eflux_model)])
   logger, 'fit residuals for ',ifix.length,'objects SNR >',self.param.fit_snrhi_psf, /info

; ----- fit brightest sources with a bit more freedom: both in profile and centroid
; @@@@@ check binning issues
   Pr = [[8.0, 0.0], [0.96, 0.0]]  & Qr = [[8.0, 0.96], [0.0, 0.0]] ; expand r
   Px = [[4.0, 0.0],  [0.98, 0.0]] & Qx = [[-4.0, 1.02], [0.0, 0.0]] ; shear x
   Py = [[-4.0, 0.0], [1.02, 0.0]] & Qy = [[4.0, 0.98], [0.0, 0.0]]  ; shear y

   kdim = src[0].dim
   k4 = (kdim/4)[0]
   bin =  self.param.fit_bin
   extast, headfits(self.fdet), ast_tmpl   ; det pixscale
   psf_basis = transpose(self.getkernel(/getbasis, ast_out=ast_tmpl))
  ; nbasis = (psf_basis.dim)[0]
   nbasis = 0
   !null = growthcurve(mophongo.getkernel(1,1,ast_out=ast_tmpl),rhalf=rhalf_phot)

   ; sigmoid weighting function
   sm = lambda(x,m,s: 1.0/(1+exp(-(x-m)/s)))
   !null = apermask(kdim[0],d=rr)
   ww = 1.0 - sm(rr, kdim[0]/4.0, kdim[0]/8.0)

   ncol = 7  + nbasis
   aa = fltarr([ncol, kdim])   ; holds basis to model residuals

  ; R = extrac(identity(ncol),0,0,ncol+2,ncol)
  ; foreach i, where(R) do R[i] *= [1,-2,1]

   ; fit residuals with new basis function set
   if ifix.length gt 0 then foreach s, src[ifix],i do begin
      model = self.make_model(src, scale, id=s.id,  distance=kdim[0]/2.0, outsize=kdim, winx=winx, winy=winy,det=det)
      if bin gt 1 then tmpl = congrid(s.tmpl, kdim[0], kdim[0], cubic=cubic, interp=interp, /center)/bin^2 else tmpl=s.tmpl

      ; @@@ check resolution effects here if binning
      phot = (*self.photimg)[winx[0]:winx[1], winy[0]:winy[1]]
      ivar = (*self.photwht)[winx[0]:winx[1], winy[0]:winy[1]]
      res =  phot-model

      iid = (where(src.id eq s.id))[0]
      iiscale = scale[iid]
      clean = res + iiscale*tmpl

      clean4 = clean[k4:3*k4,k4:3*k4]
      res4 = res[k4:3*k4,k4:3*k4]
      ivar4 = ivar[k4:3*k4,k4:3*k4]
if 0 then begin
      ; @@@@  apply residual shift to all nearby templates
      restore, self.fphot.replace('sci.fits','fit_shift.sav')
      ish=where(s.id eq id[shifts.iok],nsh)
      rsh = (shifts.zfit-shifts.z)[*,ish]
      resn = phot-imshift(model,rsh,cubic=-0.5)
      faper, (res)^2*ivar, !null, !null, rhalf_phot/3.0, fres_old, /mean, os=1
      faper, (resn)^2*ivar, !null, !null, rhalf_phot/3.0, fres_new, /mean, os=1
      inn = self.overlap(src, id=s.id, distance=kdim[0]/4.0)
      logger, 'shift',  fres_old , '->', fres_new, (fres_new lt fres_old/1.1 and scale[iid] eq max(scale[inn])) ? 'YES' : ''

      if 0 and fres_new lt fres_old/1.1 and scale[iid] eq max(scale[inn]) then begin
         foreach j,inn do src[j].tmpl = imshift(src[j].tmpl,rsh/bin, interp=1)
         model = self.make_model(src, scale, id=s.id, inn=inn, distance=kdim[0]/2.0, outsize=kdim, winx=winx, winy=winy,det=det)
         res =  phot-model
         res4 = res[k4:3*k4,k4:3*k4]
       end

      if keyword_set(stopme) then begin
         if i eq 0 then window,xs=2400,ys=400
        ; tvs, phot-imshift(model,rsh,cubic=-0.5),mm=[-1,1]*3e-4
         tvs, clean - iiscale*(tmpl),mm=[-1,1]*3e-4
         tvs, resn,mm=[-1,1]*3e-4,pos=1
         stopkey
      end
end
      gal =  tmpl
      ; extra basis functions: shift x, shift y, expand r, shear x, shear, gal
      aa[0,*,*] = (shift(gal,3,0)-shift(gal,-3,0))/2.0 * ww
      aa[1,*,*] = (shift(gal,0,3)-shift(gal,0,-3))/2.0 * ww
      aa[2,*,*] = (gal-poly_2d(gal,Pr,Qr, cubic=-0.5)) * ww
      aa[3,*,*] = (gal-poly_2d(gal,Px,Qx, cubic=-0.5)) * ww
      aa[4,*,*] = (gal-poly_2d(gal,Py,Qy, cubic=-0.5)) * ww
      aa[5,*,*] =  tmpl               ; @@@ do we fit residuals, or simulatenous fit ? @@@ is the same if LLS?
      aa[6,*,*] =  self.getkernel(s.ra,s.dec,ast_out=ast_tmpl) * ww
      if nbasis gt 0 then aa[7:*,*,*] = psf_basis[1:nbasis,*,*] * rebin(reform(ww^2,[1,ww.dim]), [nbasis, kdim])

      aa4 = reform(aa[*,k4:3*k4,k4:3*k4], ncol, (3*k4-k4+1)^2)
      aat4 = transpose(aa4)
      ata4 = aat4 ## aa4
      xx = invert(ata4) ## (aat4 ## reform(clean4, 1, (3*k4-k4+1)^2) )
      lin = reform(xx # reform(aa, ncol, model.length), model.dim)
      lin4  = lin[k4:3*k4,k4:3*k4]

      faper, (res4)^2*ivar4, !null, !null, rhalf_phot/3.0, fres_old, /mean, os=1
      faper, (clean4-lin4)^2*ivar4, !null, !null, rhalf_phot/3.0, fres_new, /mean, os=1
      statusline, 'tweaking fit '+s.id.tostring()+' '+fres_old.tostring()+' -> '+fres_new.tostring()+' : '+(fres_old/fres_new).tostring()+' better'

      ; only keep significant improvements @@@ should flag sources: hardwired
      if fres_new lt fres_old/2.0 then begin
         if not isa(iupdate) then iupdate = list(ifix[i]) else iupdate.add, ifix[i]
         scale[ifix[i]] = total(lin)
         s.tmpl =  rbin(lin/scale[ifix[i]],bin)    ; rescale residual back to normalized model
         src[ifix[i]] = s
      end

     if keyword_set(stopme) then begin
         modelt = self.make_model(src, scale, id=s.id, distance=kdim[0]/2.0, outsize=kdim, winx=winx, winy=winy)
         tvs, (phot-modelt)[k4:3*k4,k4:3*k4], pos=5, mm=[-1,1]*3e-4
         stopkey,/silent
       end
  end
   return, isa(iupdate) ? iupdate.toarray() : !null
end

; drivers
pro mophongo::totalphot
   compile_opt idl2

   logger, 'total magnitudes', /info
   for i=0L,obj.length-1 do begin
      od = self.obj[i]
      ; detection image

      od.seg = ptr_new(seg[od.xmin:od.xmax,od.ymin:od.ymax], /no_copy)
      od.img = ptr_new(det[od.xmin:od.xmax,od.ymin:od.ymax], /no_copy)

      ; psf matched detection -> store all parameters, totcor etc, here
      op = od
      op.img = ptr_new(img[op.xmin:op.xmax,op.ymin:op.ymax], /no_copy)

     !p.multi=[0,3,2]
      ; measure in color aperture on psf-matched detection image
      detect_kron, op, kron_factor=par.phot_kron, bias_shrink=par.bias_shrink, $
           bias_fraction=par.bias_fraction, blend_shrink=par.blend_shrink, minradius=par.phot_minradius/pscl

      ; measure in detection aperture on detection image
      detect_kron, od, kron_factor=par.detect_kron, bias_shrink=par.bias_shrink, $
                  bias_fraction=par.bias_fraction, blend_shrink=1.0, minradius=par.phot_minradius/pscl, noverlap=noverlap

      mask_shrink = sqrt(od.kron_area/(noverlap+od.kron_area))  ; correct kron ellipse for masked pixels
      faper,  detpsf, !null, !null, od.kron_major*mask_shrink, inv_det_apcor, elon=od.kron_major/od.kron_minor, theta=od.theta
      op.apcor = 1.0 / inv_det_apcor
      op.totcor = (od.flux_auto / op.flux_auto) * op.apcor

      if i mod 20 eq 0 then statusline, i.s()+'/'+obj.length.s()+'    '+str(100.0*i/obj.length)+"%"
      obj[i] = op


      detect_showstamp, op, minradius=par.phot_minradius/pscl, title='KRON='+str(par.phot_kron)
      detect_showstamp, od, minradius=par.phot_minradius/pscl, title='KRON='+str(par.detect_kron)
      stopkey
   end


end

pro mophongo::aperphot
   compile_opt idl2

; split off 1) loading of images, 2) photometry on single source

      i=6
  logger, froot[i]
;     i=8
      img = readfits(froot[i]+'_sci.fits',h,/silent,nan=0.0)
      con = readfits(froot[i]+'_con.fits',h,/silent,nan=0.0)
      wht = readfits(froot[i]+'_wht.fits',/silent,nan=0.0)
      rms2 = readfits(froot[i]+'_con_rms.fits',/silent,nan=0.0)
      rms = readfits(froot[i]+'_rms.fits',/silent,nan=0.0)

     faper, rms, obj.x, obj.y, obj.kron_major, fpix, elon=obj.kron_major/obj.kron_minor, theta=obj.theta, /status,/mean
     frms =  sqrt(obj.kron_area)*fpix
     faper, rms2, obj.x, obj.y, obj.kron_major, fpix2, elon=obj.kron_major/obj.kron_minor, theta=obj.theta, /status,/mean
     frms2 =  sqrt(obj.kron_area)*fpix
     faper, con, obj.x, obj.y, obj.kron_major, fcon, elon=obj.kron_major/obj.kron_minor, theta=obj.theta, /status
     faper, wht, obj.x, obj.y, obj.kron_major, fwht, elon=obj.kron_major/obj.kron_minor, theta=obj.theta, /status, /mean
  snr = fcon/frms  ; seems wrong
  print, fcon[10:17]
  print, fwht[10:17]
  print, obj[10:17].kron_area, obj[10:17].kron_major

print,median(sqrt(obj.kron_area/!pi)), median(sqrt(obj.kron_area))
print,median(sqrt(obj.kron_area/!pi))*0.06*2

end

function mophongo::psf, fwhm=fwhm, npixel=npixel, centroid=centroid, stopme=stopme, _extra=extra
  compile_opt  static
  os = 5
  if not keyword_set(centroid) then centroid = (npixel-1.)/2.
;   centroid_os = (centroid + 0.5)*os - 0.5
  centroid_os = centroid*os + 1.0

  ; offset error in centroid of psf gaussian? why need to add 1 to make it work?
  p =  psf_gaussian(fwhm=fwhm*os,npixel=npixel*os,centroid=centroid_os+1,_extra=extra)

 if keyword_set(stopme) then begin
  psfb = rbin(p,os)
  tvs,gauss2dfit(p,g)  & print,g
  tvs,gauss2dfit(psfb,g)  & print,g
  stopkey
end

  return, rbin(p,os)

; binned coordinates
;  xb = (x - 1)/3.0
;  x = xb * 3.0 + 1.0
end


;NUGGET: When the data to be fit includes noise, the Gaussian process model
;can be used by specifying the variance of the noise for each point.
;GaussianProcess takes a parameter nugget which is added to the
;diagonal of the correlation matrix between training points: in general
;this is a type of Tikhonov regularization. In the special case of a
;squared-exponential correlation function, this normalization is
;equivalent to specifying a fractional variance in the input. That is
; MODEL:
;Common correlation models matches some famous SVMs kernels because
;they are mostly built on equivalent assumptions. They must fulfill
;Mercers conditions and should additionally remain stationary. Note
;however, that the choice of the correlation model should be made in
;agreement with the known properties of the original experiment from
;which the observations come. For instance:
;If the original experiment is known to be infinitely differentiable
;(smooth), then one should use the squared-exponential correlation
;model.
;If its not, then one should rather use the exponential correlation
;model.
;Note also that there exists a correlation model that takes the degree
;of derivability as input: this is the Matern correlation model, but


;  ----- centroid on brightish sources  ----- ----- ----- ----- ----- -----
; @@@ keep inv distance for now: still small number of sources with large residuals -> fix separately
; @@@strong residual for small number of sources left (~100 bright) probabl confusion
; @@@ TODO: make comparison to true shift plot both for HST as IRAC gauss sim.plot  dx,dy for  for good and bad residuals !
; @@@ make plot with sources with no neighbours
; @@@ put kriging + parameters in param file
; @@@ regulation too string? photometry too tight?
; @@@ then move on!!!


; ------------- fit again with improved photometry + background
; @@@ note we can save the 'regularization' in a difference matrix/vector and add it back in when background etc is updated  -> means fewer iterations necessary?
   logger, 'second pass solve: improved astrometry + background', /info
   scale = self.solve(src, ata, atb, regul_neg=2, regul_res=2, fsig=fsig, fres=fres, residual=residual, stopme=stopme,interp=interp)

; ----- model residuals, return indices of sources updated
   fchi = (fres/fsig)^2
   ifix = where(scale/src.eflux_model gt self.param.fit_snrhi_psf and fchi gt 3.0*median(fchi))
   iupdate  = self.fit_residuals(src, scale, ifix, interp=interp)
   self.make_normal, src, ata, atb, update=iupdate, interp=interp

; ----------------------------------------
   logger, 'final solve linear system', /info
   scale = self.solve(src, ata, atb, regul_neg=2, regul_res=3, model=model, residual=residual, fsig=fsig, fres=fres,interp=interp)
   var =  1.0/(*self.photwht)  + (self.param.fit_syserr*model)^2


pro mophongo::fitphot
   compile_opt idl2
    if self.param.fit_interp eq 'cubic' then cubic=-0.5 else interp=1

   self.fitphot_validate_all
stop

   ptic
   ; @@@ check for existence of phot,det,and objects
   if ~isa(self) then return


   extast, headfits(self.fdet), adet
   getrot,adet,pa,pscl
   if ((*self.obj).ra)[0] eq 0.0 then begin
      xy2ad, (*self.obj).x, (*self.obj).y, adet, ra, dec
      (*self.obj).ra = ra
      (*self.obj).dec = dec
   end

;  @@@ get a typical kernel for some approximate information
   mra = median((*self.obj).ra)
   mdec = median((*self.obj).dec)
   gckern= growthcurve(self.getkernel(mra, mdec, ast_kern=akern,ast_out=adet), rhalf=rhalf_phot)
   gcpsf = growthcurve(self.getpsf(mra,mdec),rhalf=rhalf_det)
   self.param.rhalf_phot = rhalf_phot
   self.param.rhalf_det = rhalf_det

   ; auto determine binning applied to modeling if binning < 1
   if self.param.fit_bin lt 1 then self.param.fit_bin = oddsize(rhalf_phot/5.0)  ; @@@ test even
 ; self.param.fit_bin = 3     ; @@@ hardcoded
  self.param.fit_bin =1    ; @@@ hardcoded
   logger, 'binning model by ', self.param.fit_bin, ' to ',  3600*pscl[1]*self.param.fit_bin,'"/pix', /info


   src = self.make_tmpl(*self.obj )     ; stored in self.tmpl
;   ; -> AT.A = AT.b  where aij is dot product of tmpl_i src and tmpl_j and y = AT.b = tmpl_i * phot_i
   self.make_normal, src, ata, atb, noisefloor=0.1, interp=1 , /verbose

   logger, 'sparsity normal matrix:', ata.nnz/product(ata.shape.toarray())

   ; ------ solving first time....
   logger, 'solving linear system', /info
   scale = self.solve(src, ata, atb, regul_neg=2, interp=interp)

   scale = (la.cg(ata.tocsr(), atb, tol=self.param.fit_tol))[0]

   model = self.make_model(src, scale>0, residual=residual,interp=interp)

; ----- subtract background from residual map -> force fits non-negative
   self.background, src, scale > 0.0, interp=interp, /stopme

;  ----- centroid on brightish sources
   self.centroid, src, scale, interp=interp,/stopme
   atb = self.make_RHS(src, interp=interp)

; ------------- fit again with improved photometry + background
; @@@ note we can save the 'regularization' in a difference matrix/vector and add it back in when background etc is updated  -> means fewer iterations necessary?
   logger, 'second pass solve: improved astrometry + background', /info
   scale = self.solve(src, ata, atb, regul_neg=2, regul_res=2, fsig=fsig, fres=fres, residual=residual, stopme=stopme,interp=interp)

; ----- model residuals, return indices of sources updated
   fchi = (fres/fsig)^2
   ifix = where(scale/src.eflux_model gt self.param.fit_snrhi_psf and fchi gt 3.0*median(fchi))
   iupdate  = self.fit_residuals(src, scale, ifix, interp=interp)
   self.make_normal, src, ata, atb, update=iupdate, interp=interp

; ----------------------------------------
   logger, 'final solve linear system', /info
   scale = self.solve(src, ata, atb, regul_neg=2, regul_res=3, model=model, residual=residual, fsig=fsig, fres=fres,interp=interp)
   var =  1.0/(*self.photwht)  + (self.param.fit_syserr*model)^2

   cleanplot
   loadct,0,/silent
   cgWindow_SetDefs, /PS_Encapsulated, aspect=1.0, IM_Width=(residual.dim)[0]/3.0
   cgimage, (*self.photimg), layout=[1,1,1],/keep,/stretc,minv=-2e-4,maxv=2e-4, outfile='mp_img.png', output='png'
   cgimage, (model), layout=[1,1,1],/keep,/stret,minv=-2e-4,maxv=2e-4, outfile='mp_mod.png', output='png'
   cgimage, (residual) , layout=[1,1,1],/keep,/stret,minv=-2e-4,maxv=2e-4, outfile='mp_res.png', output='png'
   cgimage, (residual/sqrt(var)) , layout=[1,1,1],/keep,/stretc,minv=-3,maxv=3, outfile='mp_snr.png', output='png'
   cgimage, (*self.detimg), layout=[1,1,1],/keep,/stretc,minv=-2e1,maxv=2e1, outfile='mp_det.png', output='png'

   la = python.import('scipy.sparse.linalg')
   scale_free = (la.cg(ata, atb, tol=self.param.fit_tol))[0]

;end

;----------  threshold sparse matrix on fraction of diagional (dot product w/self)
;print,' nnz before ', ata.nnz
;   dm = (ata.diagonal()).median()
;   ata = ata.multiply(ata gt dm*self.param.fit_sparse_threshold)
;print,' nnz after ', ata.nnz

;   bbt = bb.multiply(bb gt dm*self.param.fit_sparse_threshold*10)
; tic &  bu = la.splu(bb, permc_spec='MMD_AT_PLUS_A')   & toc   ; 2.0   1.4e6
; tic &  bu = la.spilu(bb, permc_spec='MMD_AT_PLUS_A')   & toc   ; 0.6s
; tic &  bu = la.spilu(bb)   & toc
;tic & sol = la.cg(bb, atb_ok, tol=1e-6)   & toc ; 0.11s
; tic &    btu = la.splu(bbt, permc_spec='MMD_AT_PLUS_A')  & toc  ; 1.7     0.6e6
; tic &    btu = la.splu(bbt, permc_spec='MMD_AT_PLUS_A')  & toc  ; 1.7     0.6e6
;s1 =   btu.solve(atb_ok, trans='N')
;tic & tmp =  la.cg(bb, atb_ok, tol=1e-8) & s2=tmp[0]   & toc ; 0.11s
; cg veel veel sneller, maar check robustness. good second: spilu


;---------------- general utilities

; mophongo requires that basic astrometry and background is alread "close"
pro mophongo::load_detect, fdet

   if isa(fdet) then begin
      logger, 'loading '+fdet,/info

      self.fdet = fdet
      memmap = self.param.fit_memmap

      detimg = self.memmap(readfits(fdet, hdet, /silent,nan=0.0), name='det', file=memmap)
      self.detimg = ptr_new(detimg, /no_copy)

      extast, hdet, ast_det
      getrot, ast_det, pa, cdelt
      self.param.pscale_det = cdelt[1]*3600.

     ; @@@ change this, takes too much memory
      var = (readfits(fdet.replace('sci','rms'), /silent, nan=0.0))^2
      var = self.memmap(float(var ne 0.0)/(var + float(var eq 0)), name='detwht', file=memmap)
      self.detwht = ptr_new(var, /no_copy)

      ; @@@@ segmap will go.. or converted into objects file (or reverse index file)
      seg = self.memmap(readfits(fdet.replace('sci','seg'), /silent, nan=0.0), name='segmap', file=memmap)
      self.segmap = ptr_new(seg, /no_copy)

      self.fdetpsf = fdet.replace('sci.fits','psf.sav')
      detpsf = self.getpsf(1, 1, filename=self.fdetpsf)

      ; pre allocate model
      self.model = ptr_new(self.memmap(fltarr((*self.detimg).dim), name='model', file=memmap), /no_copy)
    end
end

pro mophongo::load_catalog, catfile

   ; @@@ naming of objects is inconsistent -> fix so similar to wht,rms et
   restore, catfile

   self.obj = ptr_new( obj[where(obj.use)] )

   ;!null = HISTOGRAM(*self.segmap,min=1,rev=ri)
   ;iseg = cgReverseIndices(ri, (*self.obj)[j].id-1, COUNT=cnt)
   ; ignore previous blends, note: IDs are not sequential,
   ; but assume index of original list is ID-1
   ; we would actually want to preserve and measure them, incase galaxies were erroneousl split up
end

PRO mophongo__DEFINE

 data = {mophongo, $
          name : '', $
          ID : 0L, $
          param : obj_new(), $
          catalog : ptr_new(), $  ; catalog
          starcat : ptr_new(), $  ; star catalog
          obj : ptr_new(), $  ; objects
          reverse_indices: ptr_new(), $
          model : ptr_new(), $    ; model image
          detimg : ptr_new(), $    ; detection image
          detwht : ptr_new(), $    ; detection weight, inverse variance
          segmap : ptr_new(), $    ; segmentation map
          photimg : ptr_new(), $   ; photometry img
          photwht : ptr_new(), $   ; photometry wht: unit, inverse variance
          fkern : '', $             ; from here on it can be pushed into param
          fdet : '', $      ; name currently loaded det images
          tmpl: ptr_new(), $    ; obsolete?
          fdetpsf: '', $
          fphot : '', $     ; name currently loaded phot images
          fphotpsf: '', $
          memseg : ptr_new(), $   ; photometry img
          memfile: ptr_new(), $    ; corresponding filename if mapped to disk
          memdim : ptr_new(), $    ; photometry img
          memtype : ptr_new(), $   ; photometry wht: unit, inverse variance
          inherits idl_object }
end


pro exploration_stuff
  ; foreach b, basis do wht = append(wht, *b.wht)
  ; kern = self.getkernel(1,1)
  ; sig = sqrt( 1.0/total(kern^2)/wht)
  ; sigpix = sqrt(1.0/wht)
;       1994        3172
;         769        1967

   mm = mag(basis.flux_iso,29)
   ibf = where(x_cg lt -3*sig, complement=iokf)
   ibr = where(x_cg lt -3*sig and mm lt 24, complement=iok)
   iokb  = where(x_cg gt 1000*sig)
   cgimage, model1, layout=[2,1,1],/keep,/stretc,minv=-1e-4,maxv=1e-4,/axis,xr=[1994,3172],yr=[769,1967]
   cgplots, basis[ibf].x, basis[ibf].y, psym=1,color='red'
   cgplots, basis[ibr].x, basis[ibr].y, psym=1,color='yellow'
   cgplots, basis[iokb].x, basis[iokb].y, psym=1,color='green'
   cgimage, residual1,layout=[2,1,2],/keep,/stretc,minv=-1e-4,maxv=1e-4,/axis,xr=[1994,3172],yr=[769,1967]
   cgplots, basis[ibf].x, basis[ibf].y, psym=1,color='red'
   cgplots, basis[ibr].x, basis[ibr].y, psym=1,color='yellow'
   cgplots, basis[iokb].x, basis[iokb].y, psym=1,color='green'
   cgtext, basis[iokb].x, basis[iokb].y, strn(basis[iokb].id),/data,color='green'

;   cgplothist, mm, col='red',bin=0.1, xrange=[12,29.5], layout=[2,1,1]
;   plothist, mm[ibf], col='red',/overplot,/fill,fcol='red', xrange=[12,29.5], bin=0.1

   basis = self.make_basis(src,id=6554L)
   self.make_normal, basis, ata, atb
   sol = la.cg(ata, atb, tol=1e-8)   ; 0.06s
   x_cg = sol[0]
   model1 = self.make_model(basis, x_cg, id=id, residual=residual1)

   self.make_normal, basis, ata, atb
   sol = la.cg(ata, atb, tol=1e-8)   ; 0.06s
   x_cg = sol[0]
   model2 = self.make_model(basis, x_cg, id=id, residual=residual2)
   b_6554.id = 9999
   basis = [b_6554,basis]

   self.make_normal, basis, ata, atb
   sol = la.cg(ata, atb, tol=1e-8)   ; 0.06s
   x_cg = sol[0]
   x_cg[ii] -= 10
   x_cg[-1] += 10
   bs = basis
   (*bs[ii].det) = shift(*bs[ii].det,-1,-1)
   (*bs[-1].det) = shift(*bs[-1].det,-1,-1)

   self.make_normal, basis, ata, atb
   sol = la.cg(ata, atb, tol=1e-8)

   model3 = self.make_model(basis, sol[0], id=id, residual=residual3)
;   model3 = self.make_model(basis, x, id=id, residual=residual3)

   ; add bases and rebuild normal eq
 ;  btmp = [basis[iokf],basis_bright]
   self.make_normal, btmp, ata, atb
   sol = la.cg(ata, atb, tol=1e-8)
   foreach b, btmp, i do if i eq 0 then wht = *b.wht else wht = [wht, *b.wht]
   stmp = sqrt( 1.0/total(kern^2)/wht)
   xtmp = sol[0]
   id = btmp.id

ibad = where(x_cg lt -3*sig and mm gt 22,compl=iok)
model2 = self.make_model(basis[iok], x_cg[iok], id=id, residual=residual)

; remove bas and rebuuikld
self.make_normal, basis[iok], ata, atb
sol = la.cg(ata, atb, tol=1e-8)   ; 0.06s
x_cg = sol[0]

delvarx,wht
model3 = self.make_model(basis[iok], x_cg, id=id, residual=residual)

i= where(x_cg lt -3*median(sig))
ib = where(x_cg gt 200*median(sig))
cgimage, residual,layout=[2,1,2],/keep,/stretc,minv=-1e-4,maxv=1e-4,/axis,xr=[702,4598],yr=[150,2410]
cgplots, basis[i].x, basis[i].y, psym=1,color='red'
cgplots, basis[ib].x, basis[ib].y, psym=1,color='green'

;stop
;foreach b, basis do wht = append(wht, *b.wht)
;sig = sqrt( 1.0/total(kern^2)/wht)

mbg = model lt median(sigpix)/2
tvs,mbg*residual

tt = (mbg*residual)[1200:2800,900:2000]
tt = tt[where(tt ne 0)]
plothist,tt,xr=[-1e-4,1e-4]
histogauss, tt, gg
; - 3e-6, sigma 8e-6


; ok so we can cull on dotproduct -> if < 1e-3 of the diagonal? -> check for uberbright sources
iaok = where(a/max(a) gt 1e-3)
plothist, dm[ia], bin=5,col='green'
plothist, dm[iaok],bin=5,col='green',/fill,/overplot,fcolor='green'


ddinv = diag_matrix(ainv)
LA_SVD, A, W, U, V , /divide
x_dsvd = svsol(u,w,v,atb)
; ainv_svd =  v ## diag_matrix(w^(-1)) ## transpose(u) ; ok!
; lad = Python.import('scipy.linalg')
; x_svd = svsol(uwv[0],uwv[1],uwv[2],atb,/column) ; wrong answer ?
;condition = cond(ainv, /double, lnorm=2)
plot, w
print, 'condition ',max(w)/min(w), norm(ainv)*norm(a)
;print,(MACHAR(/double)).eps
;   2.2204460e-16


  model = self.make_model(basis, x_cg)
; lots of very negative
   model = self.make_model(basis, x, id=id)

end
